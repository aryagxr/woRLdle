{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "import re\n",
    "import pandas as pd\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    # peft_config=peft_config,\n",
    "    device_map=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '<|im_start|>system\\n\\nYou are playing Wordle, a word-guessing game.\\n\\n### Game Rules:\\n- You have **6 tries** to guess a secret **5-letter** word.\\n- Each guess must be a valid **5-letter English word**.\\n- After each guess, you will receive feedback indicating how close your guess was.\\n\\n### Feedback Format:\\nEach letter in your guess will receive one of three symbols:\\n1. ✓ : The letter is in the word and in the CORRECT position.\\n2. - : The letter is in the word but in the WRONG position.\\n3. x : The letter is NOT in the word.\\n\\n### Example:\\nSecret Word: BRISK\\n\\nGuess 1: STORM → Feedback: S(-) T(x) O(x) R(-) M(x)\\nGuess 2: BRAVE → Feedback: B(✓) R(✓) A(x) V(x) E(x)\\nGuess 3: BRISK → Feedback: B(✓) R(✓) I(✓) S(✓) K(✓)\\n\\n### Response Format:\\nThink through the problem and feedback step by step. Make sure to first add your step by step thought process within <think> </think> tags. Then, return your guessed word in the following format: <guess> guessed-word </guess>.\\n<|im_end|>\\n<|im_start|>user\\nMake a new 5-letter word guess.\\n\\n Here is some previous feedback:\\nGuess 1: CRANE -> Feedback: C(x) R(x) A(-) N(-) E(x)<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>',\n",
       " 'word_list': 'https://raw.githubusercontent.com/arnavgarg1/arnavgarg1/refs/heads/main/five_letter_words.csv',\n",
       " 'past_guess_history': \"[['CRANE', 'C(x) R(x) A(-) N(-) E(x)']]\",\n",
       " 'secret': 'ANNUL'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"predibase/wordle-grpo\", split=\"train\")\n",
    "dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_csv(\"https://raw.githubusercontent.com/arnavgarg1/arnavgarg1/refs/heads/main/five_letter_words.csv\")\n",
    "valid_words = set(words[\"Word\"].str.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reward Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def regexsearch(text)->str:\n",
    "    match = re.search(r\"<guess>\\s*(\\w+)\\s*</guess>\", text)\n",
    "    return match.group(1).strip().lower() if match else \"\"\n",
    "\n",
    "\n",
    "def extractguess(completions)->list[str]:\n",
    "    # response = [c[0][\"content\"] for c in completions]\n",
    "    guesses = [regexsearch(completion) for completion in completions]\n",
    "    print(f\"[EXTRACT_GUESS] Extracted guesses: {guesses}\") # for debugging\n",
    "    return guesses\n",
    "\n",
    "\n",
    "\n",
    "# reward functions\n",
    "def finalguess(completions, secret, **kwargs) -> list[float]:\n",
    "    guesses = extractguess(completions)\n",
    "    answer = secret.strip().lower() \n",
    "    # answers = [t.strip().lower() for t in secret] * len(completions)\n",
    "    # reward = [2.0 if g == t else 0.0 for g,t in zip(guesses, answers)]\n",
    "    # print(f\"[FINAL_GUESS] Secret word: {answers[0]}\")\n",
    "    reward = [2.0 if g == answer else 0.0 for g in guesses]\n",
    "    print(f\"secre word is: {answer}\")\n",
    "    return reward\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def feedback_reward(completions, past_guess_history, **kwargs) -> list[float]:\n",
    "    print(\"=\"*50)\n",
    "    print(\"ALL COMPLETIONS:\")\n",
    "    for i, completion in enumerate(completions):\n",
    "        print(f\"\\n--- Completion {i} ---\")\n",
    "        print(completion)\n",
    "        print(f\"--- End Completion {i} ---\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    rewards = []\n",
    "    guesses = extractguess(completions)\n",
    "    print(\"Guesses: \", guesses)\n",
    "    \n",
    "    for i, g in enumerate(guesses):\n",
    "        penalty = 0.0\n",
    "        \n",
    "        history_str = past_guess_history[i] if i < len(past_guess_history) else \"[]\"\n",
    "        \n",
    "        try:\n",
    "            import ast\n",
    "            history_list = ast.literal_eval(history_str)\n",
    "            print(f\"Guess {i} ('{g}') - Parsed history: {history_list}\")\n",
    "            \n",
    "            for word, feedback in history_list:\n",
    "                print(f\"  Processing: word='{word}', feedback='{feedback}'\")\n",
    "                parsed = re.findall(r\"([A-Z])\\((.)\\)\", feedback)\n",
    "                \n",
    "                for pos, (letter, status) in enumerate(parsed):\n",
    "                    letter = letter.lower()\n",
    "                    \n",
    "                    if status == \"x\":\n",
    "                        if letter in g:\n",
    "                            penalty += 0.1\n",
    "                            print(f\"    Penalty +0.1: '{letter}' marked as (x) but found in guess\")\n",
    "                    \n",
    "                    elif status == \"-\":\n",
    "                        if letter not in g:\n",
    "                            penalty += 0.1\n",
    "                            print(f\"    Penalty +0.1: '{letter}' marked as (-) but not in guess\")\n",
    "                        elif pos < len(g) and g[pos] == letter:\n",
    "                            penalty += 0.1\n",
    "                            print(f\"    Penalty +0.1: '{letter}' marked as (-) but in same position\")\n",
    "                    \n",
    "                    elif status == \"✓\":\n",
    "                        if pos >= len(g) or g[pos] != letter:\n",
    "                            penalty += 0.2\n",
    "                            print(f\"    Penalty +0.2: '{letter}' marked as (✓) but not in correct position\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing history for guess {i}: {e}\")\n",
    "            penalty = 0.0\n",
    "        \n",
    "        reward = max(0.0, 1.0 - penalty)\n",
    "        rewards.append(reward)\n",
    "        print(f\"  Final penalty: {penalty}, reward: {reward}\")\n",
    "    \n",
    "    print(f\"Final rewards: {rewards}\")\n",
    "    return rewards\n",
    "\n",
    "\n",
    "def validword(completions, **kwargs) -> list[float]:\n",
    "    guesses = extractguess(completions)\n",
    "    rewards = []\n",
    "    for g in guesses:\n",
    "        penalty = 0.0\n",
    "        penalty += 0.5 if len(g) != 5 else 0.0\n",
    "        penalty += 0.5 if g not in valid_words else 0.0\n",
    "        reward = max(0.0, 1.0-penalty)\n",
    "        rewards.append(reward)\n",
    "    return rewards\n",
    "\n",
    "\n",
    "\n",
    "def xmlformat(completions, **kwargs) -> list[float]:\n",
    "    pattern = r\"<think>.*?</think>\\s*<guess>.*?</guess>\"\n",
    "    rewards = []\n",
    "    \n",
    "    for completion in completions:\n",
    "        match = re.search(pattern, completion, flags=re.DOTALL)\n",
    "        reward = 1.0 if match else 0.0\n",
    "        rewards.append(reward)\n",
    "    \n",
    "    return rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = GRPOConfig(output_dir=\"Qwen2.5-1.5B-GRPO\",\n",
    "                           num_generations=4,\n",
    "                           log_completions=True,\n",
    "                           num_completions_to_print=4,\n",
    "                           learning_rate=5e-6,\n",
    "                           temperature=0.8,\n",
    "                           top_p=0.9,\n",
    "                           top_k=50,\n",
    "                           gradient_accumulation_steps=4,\n",
    "                           per_device_train_batch_size=1,\n",
    "                           report_to=\"wandb\",\n",
    "                           run_name=\"wordle-grpo\"\n",
    "                           \n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GRPOTrainer(\n",
    "        model=model,\n",
    "        reward_funcs=[\n",
    "            finalguess,\n",
    "            feedback_reward,\n",
    "            validword,\n",
    "            xmlformat\n",
    "            ],\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "    )\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
